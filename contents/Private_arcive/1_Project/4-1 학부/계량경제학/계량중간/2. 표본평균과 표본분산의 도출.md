###### 1. 모형의 설정
- 모평균 → 확률변수 yi가 취할 수 있는 모든 값의 평균이 $\mu: E(y_{i})=\mu$
- 모분산 → 분산이 $\sigma^{2}: E((y_{i}-\mu)^{2})=\sigma^{2}$ 이라고 할 때, 다음을 모형으로
- Population Equation : $y_{i}=\mu+e_{i}$ $(i=(1,2,...,N)$ 고전적 가정) with,
	1) $\forall i, E(e_{i})=0.$ ( $\because y_{i}-\mu=e_{i}, E(y_{i}-\mu)=E(e_{i})=0;$ )
	2) $E(e_{i}^{2})=\sigma^{2},$ $\forall i$ (var def 대입)    3) $E(e_{i}e_{j})=0,$ $\forall i, j$ (cov def 대입)
---
###### 2. 최소제곱법(OLS) : 잔차항의 제곱의 합을 극소화 하는 방법 (µ추정 방식 중 하나)
- 표본회귀식: $y_{i}=\hat{\mu}+\hat{e}_{i}$ (in real life)
- OLS추정량 → $min\sum_{i=1}^{n}\hat{e}_{i}^{2}$ (with respect to $\hat{\mu}$)    (F.O.C.) $\frac{d\sum\hat{e_{i}}^{2}}{d\hat{\mu}}=0 \rightarrow \hat{\mu}=\frac{1}{n}\Sigma Y_{i}$
---
###### 3. OLS 추정량의 불편성(unbiasedness): $E(\hat{\theta})=\theta$ (성립시 unbiased estimator)
- (unbiased estimator) = (Repeated sampling 에서 평균적으로 $\theta$의 값을 준다.)
- $E(\hat{\mu})= (\text{n*μ 방식}) = (\text{pop e.q. 방식}) = \mu$
---
###### 4. OLS 추정량의 분산+가정 : $E(e_ie_j)=0,i\neq j$
- $Var(\hat{\mu})=E[(\hat{\mu}-E(\hat{\mu})(=\mu))^{2}]=E[(\frac{\Sigma e_{i}}{n})^{2}]=\frac{\sigma^{2}}{n}$ ($\because E(e_{i}^{2})=\sigma^{2}, \forall i$ , $E(e_{i}e_{j}) = 0, i \neq j$)
---
###### 5. 표본 분산의 평균
1) known $\mu: \hat{\sigma}^{2}=\frac{1}{n}\Sigma_{i=1}^{n}e_{i}^{2}$
    - $\text{w.t.s.  } E(\hat{\sigma^{2}})=\sigma^{2}(u.b.e.)$, $E(\frac{\Sigma e_{i}^{2}}{n})=\sigma^{2}$
    - $(\text{pop e.q.}) Y_{i}=\mu+e_{i} \rightarrow \hat{\sigma^{2}}=\frac{1}{n}\Sigma e_{i}^{2}=\frac{1}{n}\Sigma(Y_{i}-\mu)^{2}$ ($\mu,Y_i$가 known? $e_i$도 known)
2) unknown $\mu: \hat{\sigma^{2}}=\frac{1}{n-1}\Sigma_{i=1}^{n}\hat{e}_{i}^{2}$
    - $e_{i}=(Y_{i}-\mu) = (Y_{i}-\hat{\mu})+(\hat{\mu}-\mu)=\hat{e}_{i}+(\hat{\mu}-\mu)$
    - $E(\sum_{i=1}^{n}e_{i}^{2})=E(\sum_{i=1}^{n}(\hat{e_{i}}+(\hat{\mu}-\mu))^{2})= E(\sum\hat{e_i}^2)+\sigma^2$
      $=n*\sigma^2(\because E(e_i^2)=\sigma^2,\forall i) \to (n-1)\sigma^2=E(\sum\hat{e_i^2})$    $(\hat{\sigma}^2=\frac{1}{n-1}\sum\hat{e_i^2}),\quad \therefore E(\hat{\sigma}^2)=\sigma^2$
---
###### 6. 표본분산의 분산에 대한 추정 $Y_{i} = \mu + e_{i}, e_{i} \sim iid N(0, \sigma^{2}), E(\bar{y}=\mu), Var(\bar{y})=\frac{\sigma^2}{n}$
- y의 분포? 1) $\sigma^{2}$ is known, 2) $\sigma^{2}$ is unknown
    1) $\sigma^{2}$ is known: let $Z_{i}=\frac{e_{i}}{\sigma}\sim N(0,1); \quad Z_{1}^{2}+\cdot\cdot\cdot+Z_{n}^{2}\rightarrow\Sigma_{i=1}^{n}(\frac{e_{i}}{\sigma})^{2}\sim\chi^{2}(n)$
        - $\sum_{i=1}^{n}Z_{i}^{2}\sim\chi^{2}(n); \quad e_{i}=y_{i}-\mu \rightarrow \hat{e}_{i}=y_{i}-\hat{\mu} \rightarrow \frac{\Sigma\hat{e}_{i}^{2}}{\sigma^{2}}\sim\chi^{2}(n-1)$
    2) $\sigma^{2}$ is unknown: $\hat{e_{i}}=y_{i}-\hat{\mu}, \frac{\Sigma\hat{e}_{i}^{2}}{\sigma^{2}}\sim\chi^{2}(n-1);\quad$ $\frac{\Sigma \hat{e}_{i}^{2}}{n-1}=\hat{\sigma^{2}}, \frac{(n-1)\hat{\sigma^{2}}}{\sigma^{2}}\sim\chi^{2}(n-1)$
        - $E(\hat{\sigma}^2)=\sigma^2=?\quad$** Note: $X\sim\chi^{2}(p) \rightarrow E(X)=p, Var(X)=2p$
        - $E(\frac{(n-1)\hat{\sigma^{2}}}{\sigma^{2}})=n-1, E(\hat{\sigma}^{2})=\sigma^{2}$    $Var(\frac{(n-1)\hat{\sigma^{2}}}{\sigma^{2}})=2(n-1)$
          $\rightarrow\frac{(n-1)^{2}}{\sigma^{4}}Var(\hat{\sigma^{2}})=2(n-1), Var(\hat{\sigma^{2}})=\frac{2\sigma^{4}}{n-1}$